{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02fcafa1",
   "metadata": {},
   "source": [
    "<h2> I am going to import the required libraries to clean the dataset </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cbf329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a1dd921",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Raw Data/autoinsurance_churn.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2810ec",
   "metadata": {},
   "source": [
    "<h3> Checking the dimensions of the dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90cca43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1680909, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc410d4",
   "metadata": {},
   "source": [
    "<h3> Printing the first 5 values to take a glimpse at the data </h3>\n",
    "<p> Going to set the max_columns to 'None', so that it shows all the rows without deprecating them. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "378c6ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individual_id</th>\n",
       "      <th>address_id</th>\n",
       "      <th>curr_ann_amt</th>\n",
       "      <th>days_tenure</th>\n",
       "      <th>cust_orig_date</th>\n",
       "      <th>age_in_years</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>income</th>\n",
       "      <th>has_children</th>\n",
       "      <th>length_of_residence</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>home_market_value</th>\n",
       "      <th>home_owner</th>\n",
       "      <th>college_degree</th>\n",
       "      <th>good_credit</th>\n",
       "      <th>acct_suspd_date</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.213000e+11</td>\n",
       "      <td>5.213000e+11</td>\n",
       "      <td>818.877997</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>2018-12-09</td>\n",
       "      <td>44</td>\n",
       "      <td>1978-06-23</td>\n",
       "      <td>32.578829</td>\n",
       "      <td>-96.305006</td>\n",
       "      <td>Kaufman</td>\n",
       "      <td>TX</td>\n",
       "      <td>Kaufman</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>50000 - 74999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.213001e+11</td>\n",
       "      <td>5.213001e+11</td>\n",
       "      <td>974.199182</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>72</td>\n",
       "      <td>1950-05-30</td>\n",
       "      <td>32.732209</td>\n",
       "      <td>-97.000893</td>\n",
       "      <td>Grand Prairie</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>27500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>50000 - 74999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.213007e+11</td>\n",
       "      <td>5.213002e+11</td>\n",
       "      <td>967.375112</td>\n",
       "      <td>4818.0</td>\n",
       "      <td>2009-09-23</td>\n",
       "      <td>55</td>\n",
       "      <td>1967-07-07</td>\n",
       "      <td>32.819777</td>\n",
       "      <td>-96.846938</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>75000 - 99999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.213016e+11</td>\n",
       "      <td>5.213006e+11</td>\n",
       "      <td>992.409561</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>53</td>\n",
       "      <td>1969-05-25</td>\n",
       "      <td>32.684065</td>\n",
       "      <td>-97.162180</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>TX</td>\n",
       "      <td>Tarrant</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>175000 - 199999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.213016e+11</td>\n",
       "      <td>5.213006e+11</td>\n",
       "      <td>784.633494</td>\n",
       "      <td>5896.0</td>\n",
       "      <td>2006-10-11</td>\n",
       "      <td>50</td>\n",
       "      <td>1972-09-25</td>\n",
       "      <td>32.751398</td>\n",
       "      <td>-97.376745</td>\n",
       "      <td>Fort Worth</td>\n",
       "      <td>TX</td>\n",
       "      <td>Tarrant</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>225000 - 249999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   individual_id    address_id  curr_ann_amt  days_tenure cust_orig_date  \\\n",
       "0   2.213000e+11  5.213000e+11    818.877997       1454.0     2018-12-09   \n",
       "1   2.213001e+11  5.213001e+11    974.199182       1795.0     2018-01-02   \n",
       "2   2.213007e+11  5.213002e+11    967.375112       4818.0     2009-09-23   \n",
       "3   2.213016e+11  5.213006e+11    992.409561        130.0     2022-07-25   \n",
       "4   2.213016e+11  5.213006e+11    784.633494       5896.0     2006-10-11   \n",
       "\n",
       "   age_in_years date_of_birth   latitude  longitude           city state  \\\n",
       "0            44    1978-06-23  32.578829 -96.305006        Kaufman    TX   \n",
       "1            72    1950-05-30  32.732209 -97.000893  Grand Prairie    TX   \n",
       "2            55    1967-07-07  32.819777 -96.846938         Dallas    TX   \n",
       "3            53    1969-05-25  32.684065 -97.162180      Arlington    TX   \n",
       "4            50    1972-09-25  32.751398 -97.376745     Fort Worth    TX   \n",
       "\n",
       "    county    income  has_children  length_of_residence marital_status  \\\n",
       "0  Kaufman   22500.0           1.0                 15.0        Married   \n",
       "1   Dallas   27500.0           0.0                  2.0         Single   \n",
       "2   Dallas   42500.0           0.0                 10.0        Married   \n",
       "3  Tarrant  125000.0           1.0                  6.0        Married   \n",
       "4  Tarrant   87500.0           1.0                  4.0        Married   \n",
       "\n",
       "  home_market_value  home_owner  college_degree  good_credit acct_suspd_date  \\\n",
       "0     50000 - 74999         1.0             1.0          1.0             NaN   \n",
       "1     50000 - 74999         1.0             0.0          0.0             NaN   \n",
       "2     75000 - 99999         1.0             0.0          0.0             NaN   \n",
       "3   175000 - 199999         1.0             0.0          1.0      2021-12-22   \n",
       "4   225000 - 249999         1.0             1.0          1.0             NaN   \n",
       "\n",
       "   Churn  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      1  \n",
       "4      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de70da39",
   "metadata": {},
   "source": [
    "<h3> Lets check if we have any duplicated records in our dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b3e3c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6eae34",
   "metadata": {},
   "source": [
    "<p> Looks like we fortunately do not have any duplicate records in our dataset and it is safe to proceed to the next step. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751a0c71",
   "metadata": {},
   "source": [
    "<h3> Now, I am Going to describe the dataset to get a basic overview of all the columns </h3>\n",
    "<p> We will describr the <b>number</b> type columns and the <b>object</b> type columns separately, since the aggregate functions for each data type are different and keeping them together would not be ideal. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f5bb1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191fbc9f",
   "metadata": {},
   "source": [
    "<p> I have set the display format to display the values with 2 float points precision, without which the numbers are going to be shown with a scientific notation, which can be difficult to interpret. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b74d7416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individual_id</th>\n",
       "      <th>address_id</th>\n",
       "      <th>curr_ann_amt</th>\n",
       "      <th>days_tenure</th>\n",
       "      <th>age_in_years</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>income</th>\n",
       "      <th>has_children</th>\n",
       "      <th>length_of_residence</th>\n",
       "      <th>home_owner</th>\n",
       "      <th>college_degree</th>\n",
       "      <th>good_credit</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1680909.00</td>\n",
       "      <td>1680909.00</td>\n",
       "      <td>1680909.00</td>\n",
       "      <td>1680909.00</td>\n",
       "      <td>1680909.00</td>\n",
       "      <td>1427190.00</td>\n",
       "      <td>1427190.00</td>\n",
       "      <td>1680909.00</td>\n",
       "      <td>1680909.00</td>\n",
       "      <td>1680909.00</td>\n",
       "      <td>1680909.00</td>\n",
       "      <td>1680909.00</td>\n",
       "      <td>1680909.00</td>\n",
       "      <td>1680909.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>221301772745.74</td>\n",
       "      <td>521300683122.30</td>\n",
       "      <td>940.31</td>\n",
       "      <td>3602.01</td>\n",
       "      <td>55.82</td>\n",
       "      <td>32.85</td>\n",
       "      <td>-96.95</td>\n",
       "      <td>81497.73</td>\n",
       "      <td>0.52</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>992632.69</td>\n",
       "      <td>417471.09</td>\n",
       "      <td>246.54</td>\n",
       "      <td>2341.00</td>\n",
       "      <td>14.55</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>54381.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>221300000003.00</td>\n",
       "      <td>521300000001.00</td>\n",
       "      <td>-194.31</td>\n",
       "      <td>20.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>31.99</td>\n",
       "      <td>-98.02</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>221300905556.00</td>\n",
       "      <td>521300332982.00</td>\n",
       "      <td>772.10</td>\n",
       "      <td>1398.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>32.71</td>\n",
       "      <td>-97.17</td>\n",
       "      <td>47500.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>221301808174.00</td>\n",
       "      <td>521300655449.00</td>\n",
       "      <td>935.01</td>\n",
       "      <td>3651.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>32.85</td>\n",
       "      <td>-96.90</td>\n",
       "      <td>70000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>221302711304.00</td>\n",
       "      <td>521300982572.00</td>\n",
       "      <td>1102.99</td>\n",
       "      <td>6291.00</td>\n",
       "      <td>64.00</td>\n",
       "      <td>32.98</td>\n",
       "      <td>-96.72</td>\n",
       "      <td>87500.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>221303307751.00</td>\n",
       "      <td>521301537315.00</td>\n",
       "      <td>2269.37</td>\n",
       "      <td>6291.00</td>\n",
       "      <td>114.00</td>\n",
       "      <td>33.55</td>\n",
       "      <td>-96.07</td>\n",
       "      <td>250000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        individual_id      address_id  curr_ann_amt  days_tenure  \\\n",
       "count      1680909.00      1680909.00    1680909.00   1680909.00   \n",
       "mean  221301772745.74 521300683122.30        940.31      3602.01   \n",
       "std         992632.69       417471.09        246.54      2341.00   \n",
       "min   221300000003.00 521300000001.00       -194.31        20.00   \n",
       "25%   221300905556.00 521300332982.00        772.10      1398.00   \n",
       "50%   221301808174.00 521300655449.00        935.01      3651.00   \n",
       "75%   221302711304.00 521300982572.00       1102.99      6291.00   \n",
       "max   221303307751.00 521301537315.00       2269.37      6291.00   \n",
       "\n",
       "       age_in_years   latitude  longitude     income  has_children  \\\n",
       "count    1680909.00 1427190.00 1427190.00 1680909.00    1680909.00   \n",
       "mean          55.82      32.85     -96.95   81497.73          0.52   \n",
       "std           14.55       0.19       0.30   54381.00          0.50   \n",
       "min           23.00      31.99     -98.02    5000.00          0.00   \n",
       "25%           45.00      32.71     -97.17   47500.00          0.00   \n",
       "50%           55.00      32.85     -96.90   70000.00          1.00   \n",
       "75%           64.00      32.98     -96.72   87500.00          1.00   \n",
       "max          114.00      33.55     -96.07  250000.00          1.00   \n",
       "\n",
       "       length_of_residence  home_owner  college_degree  good_credit      Churn  \n",
       "count           1680909.00  1680909.00      1680909.00   1680909.00 1680909.00  \n",
       "mean                  7.50        0.82            0.35         0.84       0.12  \n",
       "std                   5.14        0.38            0.48         0.37       0.32  \n",
       "min                   0.00        0.00            0.00         0.00       0.00  \n",
       "25%                   3.00        1.00            0.00         1.00       0.00  \n",
       "50%                   6.80        1.00            0.00         1.00       0.00  \n",
       "75%                  13.00        1.00            1.00         1.00       0.00  \n",
       "max                  15.00        1.00            1.00         1.00       1.00  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a191a7",
   "metadata": {},
   "source": [
    "<list>\n",
    "    <li>\n",
    "        Both the id columns are for identification purposes, which may have references to their real id. They have a large id number but we can just leave it like that, since we have no real use with them.\n",
    "    </li>\n",
    "    <li>\n",
    "        The curr_ann_amount means the current amount the customer is paying for the insurance anually. It looks like there might be a few values that are negative which are un-realistic. This column need further investigation.\n",
    "    </li>\n",
    "    <li>\n",
    "        Looks like the latitude and longitude columns have missing values. We will see if we can impute the missing values in these columns based on any other column, if not we will need to drop the records that have the missing values. Since we want to build a dashboard for the customer churn, it is not ideal to have missing values of the co-ordinates.\n",
    "    </li>\n",
    "</list>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42ffaf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_orig_date</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>home_market_value</th>\n",
       "      <th>acct_suspd_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1680909</td>\n",
       "      <td>1680909</td>\n",
       "      <td>1668842</td>\n",
       "      <td>1680909</td>\n",
       "      <td>1668842</td>\n",
       "      <td>1680909</td>\n",
       "      <td>1588623</td>\n",
       "      <td>193456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5244</td>\n",
       "      <td>1085</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>1967-07-07</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Married</td>\n",
       "      <td>75000 - 99999</td>\n",
       "      <td>2022-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>495114</td>\n",
       "      <td>142238</td>\n",
       "      <td>305939</td>\n",
       "      <td>1680909</td>\n",
       "      <td>623980</td>\n",
       "      <td>1048453</td>\n",
       "      <td>306463</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cust_orig_date date_of_birth     city    state   county marital_status  \\\n",
       "count         1680909       1680909  1668842  1680909  1668842        1680909   \n",
       "unique           5244          1085       95        1       14              2   \n",
       "top        2005-09-11    1967-07-07   Dallas       TX   Dallas        Married   \n",
       "freq           495114        142238   305939  1680909   623980        1048453   \n",
       "\n",
       "       home_market_value acct_suspd_date  \n",
       "count            1588623          193456  \n",
       "unique                19             300  \n",
       "top        75000 - 99999      2022-08-14  \n",
       "freq              306463             713  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1223f35",
   "metadata": {},
   "source": [
    "<list>\n",
    "    <li>\n",
    "        We have very few missing city and county values, which will be dropped, since it looks like there is no scope to replace them with any related column and the only way is to replace them with the mode of the county column.\n",
    "    </li>\n",
    "    <li>\n",
    "        The home_market_value has a few missing values, which we will see if we can impute based on other related columns. Also the values are not numeric but ranges of type object. We will investigate further and make a decision whether to change the values to float or just leave them as they are.\n",
    "    </li>\n",
    "    <li>\n",
    "        The acct_suspd_date is the date when the customer ended their insurance with the company. Although there are less churned records compared to the 1.68 million records it is safe to keep the column and check if we have any patterns among the churned customers.\n",
    "    </li>\n",
    "</list>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d99db",
   "metadata": {},
   "source": [
    "<h3> Dropping the records that have their <b>county</b> values missing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40d2cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['county'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ab5ad36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1668842, 22)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c29b71",
   "metadata": {},
   "source": [
    "<p> A total of 12,067 records are dropped from the dataset </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c089c9b",
   "metadata": {},
   "source": [
    "<h3> Now let's take a look at the city column </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e174268c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['city'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addae01c",
   "metadata": {},
   "source": [
    "<p> Looks like missing values in the city and county column are missing as pairs. Since the number of missing values in the city column are 0 now it is safe to proceed to the next steps. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2840ff0",
   "metadata": {},
   "source": [
    "<h3> Imputing missing values in latitude and longitude columns </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12751932",
   "metadata": {},
   "source": [
    "We are going to\n",
    "<list>\n",
    "    <li>\n",
    "        Use median as our imputation metric\n",
    "    </li>\n",
    "    <li>\n",
    "        Since latitude and longitudes are location specific and one median value is not going make sense, we will be calculating the median values for each city and impute in the respective latitude and longitude.\n",
    "</list>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6dccf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latitude'] = df.groupby('city')['latitude'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8606a380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['longitude'] = df.groupby('city')['longitude'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13bf82c",
   "metadata": {},
   "source": [
    "<p> Let us make sure we do not have any more missing values in the latitude and longitude columns </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "551b3d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude     0\n",
       "longitude    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['latitude', 'longitude']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05493c36",
   "metadata": {},
   "source": [
    "We used the median by city over the KNN-Imputation for the following reasons.\n",
    "<list>\n",
    "    <li>\n",
    "        The computation costs for 1.6 million records will be astronomical, which will lead to very slow processing times without significant hardware resources.\n",
    "    </li>\n",
    "    <li>\n",
    "        As the number of records increases KNN imputation's performance also decreases, which makes median by city (or) county a far better option.\n",
    "    </li>\n",
    "    </list>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a075027",
   "metadata": {},
   "source": [
    "<h3>Imputing missing values in home_market_value column</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60208996",
   "metadata": {},
   "source": [
    "<p>Since our main aim is to analyze the reasons for churn among the customers and suggest necessary steps to reduce it, we will not be performing any statistical analysis on the home_market_value's. Hence the best case will be to keep the <b>home_market_value</b> as a <b>object</b> type column.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2dde6c",
   "metadata": {},
   "source": [
    "<p>We will group the records based on the city, latitude and longitude values then impute the values using mode value. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a72af",
   "metadata": {},
   "source": [
    "<p> Both our latitude and longitude values have 6 decimal places. But we do not want to be using 6 decimal places when we group, since there will be a lot of groups and it is highly probable that groups may contain very few records which woud not be the best case senario. </p>\n",
    "<p> To prevent this we will round up the latitude and longitude values to two decimal places into two new columns latitude_rounded, longitude_rounded.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29d38d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latitude_rounded'] = df['latitude'].round(2)\n",
    "df['longitude_rounded'] = df['longitude'].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4815ea03",
   "metadata": {},
   "source": [
    "<p> Since we got the rounded latitude and longitude values, our next step would be to impute the missing values with mode. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e23afdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_mode(series):\n",
    "    mode = series.mode()\n",
    "    if not mode.empty:\n",
    "        return series.fillna(mode[0])\n",
    "    else:\n",
    "        return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa4b4265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['home_market_value'] = df.groupby(['city', 'latitude_rounded', 'longitude_rounded'])['home_market_value'].transform(impute_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9508bc",
   "metadata": {},
   "source": [
    "<p>Let us check and make sure there aren't anymore missing values in <b>home_market_value</b> column</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a42c46aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['home_market_value'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e29eee6",
   "metadata": {},
   "source": [
    "<p>Looks like we still have a few missing values to deal with.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e051a45",
   "metadata": {},
   "source": [
    "<p>What may have happened is</p>\n",
    "<list>\n",
    "    <li>\n",
    "        The groupings would have resulted in just a single record which does not have any other values in the group to impute with.\n",
    "    </li>\n",
    "    <li>\n",
    "        All the values in the group might have been missing and hence there are no non-missing values to impute them with.\n",
    "    </li>\n",
    "    </list>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3aa3e3",
   "metadata": {},
   "source": [
    "<p>We can impute the remaining missing values by group them by just the city column</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b63cb984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['home_market_value'] = df.groupby('city')['home_market_value'].transform(impute_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8e370",
   "metadata": {},
   "source": [
    "Let's once again check if we have any missing values left in the <b>home_market_value</b> column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fe32b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['home_market_value'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de97e7",
   "metadata": {},
   "source": [
    "<p>Since there are no missing values left, let us check if there are any columns with missing values we need to deal with.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72b8733b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "individual_id                0\n",
       "address_id                   0\n",
       "curr_ann_amt                 0\n",
       "days_tenure                  0\n",
       "cust_orig_date               0\n",
       "age_in_years                 0\n",
       "date_of_birth                0\n",
       "latitude                     0\n",
       "longitude                    0\n",
       "city                         0\n",
       "state                        0\n",
       "county                       0\n",
       "income                       0\n",
       "has_children                 0\n",
       "length_of_residence          0\n",
       "marital_status               0\n",
       "home_market_value            0\n",
       "home_owner                   0\n",
       "college_degree               0\n",
       "good_credit                  0\n",
       "acct_suspd_date        1476839\n",
       "Churn                        0\n",
       "latitude_rounded             0\n",
       "longitude_rounded            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5bc43",
   "metadata": {},
   "source": [
    "<p>There is only one column with missing values, but it is the account suspension date which only churned customer have, so we can leave the column as it is and proceed to further analysis.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361d7183",
   "metadata": {},
   "source": [
    "<h3>Converting Binary columns from float to Integer</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bdc6cf",
   "metadata": {},
   "source": [
    "<p>Columns such as <b> 'has_children', 'home_owner', 'college_degree' and 'good_credit'</b> are just to indicate just Yes or No, but they are of type float.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3420033",
   "metadata": {},
   "source": [
    "<p>All those columns can be converted to <b>Integer</b> type for better memory efficency and clarity</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c8ba29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = ['has_children', 'home_owner', 'college_degree', 'good_credit']  # add other binary columns as needed\n",
    "df[binary_cols] = df[binary_cols].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fd55e5",
   "metadata": {},
   "source": [
    "<p>Let us make sure all the columns are in our desired data type and the above columns are converted to Integer type</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21407fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "individual_id          float64\n",
       "address_id             float64\n",
       "curr_ann_amt           float64\n",
       "days_tenure            float64\n",
       "cust_orig_date          object\n",
       "age_in_years             int64\n",
       "date_of_birth           object\n",
       "latitude               float64\n",
       "longitude              float64\n",
       "city                    object\n",
       "state                   object\n",
       "county                  object\n",
       "income                 float64\n",
       "has_children             int64\n",
       "length_of_residence    float64\n",
       "marital_status          object\n",
       "home_market_value       object\n",
       "home_owner               int64\n",
       "college_degree           int64\n",
       "good_credit              int64\n",
       "acct_suspd_date         object\n",
       "Churn                    int64\n",
       "latitude_rounded       float64\n",
       "longitude_rounded      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e06a23ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individual_id</th>\n",
       "      <th>address_id</th>\n",
       "      <th>curr_ann_amt</th>\n",
       "      <th>days_tenure</th>\n",
       "      <th>cust_orig_date</th>\n",
       "      <th>age_in_years</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>income</th>\n",
       "      <th>has_children</th>\n",
       "      <th>length_of_residence</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>home_market_value</th>\n",
       "      <th>home_owner</th>\n",
       "      <th>college_degree</th>\n",
       "      <th>good_credit</th>\n",
       "      <th>acct_suspd_date</th>\n",
       "      <th>Churn</th>\n",
       "      <th>latitude_rounded</th>\n",
       "      <th>longitude_rounded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221300017872.00</td>\n",
       "      <td>521300005982.00</td>\n",
       "      <td>818.88</td>\n",
       "      <td>1454.00</td>\n",
       "      <td>2018-12-09</td>\n",
       "      <td>44</td>\n",
       "      <td>1978-06-23</td>\n",
       "      <td>32.58</td>\n",
       "      <td>-96.31</td>\n",
       "      <td>Kaufman</td>\n",
       "      <td>TX</td>\n",
       "      <td>Kaufman</td>\n",
       "      <td>22500.00</td>\n",
       "      <td>1</td>\n",
       "      <td>15.00</td>\n",
       "      <td>Married</td>\n",
       "      <td>50000 - 74999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>32.58</td>\n",
       "      <td>-96.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221300134410.00</td>\n",
       "      <td>521300051115.00</td>\n",
       "      <td>974.20</td>\n",
       "      <td>1795.00</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>72</td>\n",
       "      <td>1950-05-30</td>\n",
       "      <td>32.73</td>\n",
       "      <td>-97.00</td>\n",
       "      <td>Grand Prairie</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>27500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Single</td>\n",
       "      <td>50000 - 74999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>32.73</td>\n",
       "      <td>-97.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221300673028.00</td>\n",
       "      <td>521300247929.00</td>\n",
       "      <td>967.38</td>\n",
       "      <td>4818.00</td>\n",
       "      <td>2009-09-23</td>\n",
       "      <td>55</td>\n",
       "      <td>1967-07-07</td>\n",
       "      <td>32.82</td>\n",
       "      <td>-96.85</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>42500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>Married</td>\n",
       "      <td>75000 - 99999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>32.82</td>\n",
       "      <td>-96.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221301573419.00</td>\n",
       "      <td>521300570147.00</td>\n",
       "      <td>992.41</td>\n",
       "      <td>130.00</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>53</td>\n",
       "      <td>1969-05-25</td>\n",
       "      <td>32.68</td>\n",
       "      <td>-97.16</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>TX</td>\n",
       "      <td>Tarrant</td>\n",
       "      <td>125000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.00</td>\n",
       "      <td>Married</td>\n",
       "      <td>175000 - 199999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>1</td>\n",
       "      <td>32.68</td>\n",
       "      <td>-97.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221301622347.00</td>\n",
       "      <td>521300588399.00</td>\n",
       "      <td>784.63</td>\n",
       "      <td>5896.00</td>\n",
       "      <td>2006-10-11</td>\n",
       "      <td>50</td>\n",
       "      <td>1972-09-25</td>\n",
       "      <td>32.75</td>\n",
       "      <td>-97.38</td>\n",
       "      <td>Fort Worth</td>\n",
       "      <td>TX</td>\n",
       "      <td>Tarrant</td>\n",
       "      <td>87500.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Married</td>\n",
       "      <td>225000 - 249999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>32.75</td>\n",
       "      <td>-97.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    individual_id      address_id  curr_ann_amt  days_tenure cust_orig_date  \\\n",
       "0 221300017872.00 521300005982.00        818.88      1454.00     2018-12-09   \n",
       "1 221300134410.00 521300051115.00        974.20      1795.00     2018-01-02   \n",
       "2 221300673028.00 521300247929.00        967.38      4818.00     2009-09-23   \n",
       "3 221301573419.00 521300570147.00        992.41       130.00     2022-07-25   \n",
       "4 221301622347.00 521300588399.00        784.63      5896.00     2006-10-11   \n",
       "\n",
       "   age_in_years date_of_birth  latitude  longitude           city state  \\\n",
       "0            44    1978-06-23     32.58     -96.31        Kaufman    TX   \n",
       "1            72    1950-05-30     32.73     -97.00  Grand Prairie    TX   \n",
       "2            55    1967-07-07     32.82     -96.85         Dallas    TX   \n",
       "3            53    1969-05-25     32.68     -97.16      Arlington    TX   \n",
       "4            50    1972-09-25     32.75     -97.38     Fort Worth    TX   \n",
       "\n",
       "    county    income  has_children  length_of_residence marital_status  \\\n",
       "0  Kaufman  22500.00             1                15.00        Married   \n",
       "1   Dallas  27500.00             0                 2.00         Single   \n",
       "2   Dallas  42500.00             0                10.00        Married   \n",
       "3  Tarrant 125000.00             1                 6.00        Married   \n",
       "4  Tarrant  87500.00             1                 4.00        Married   \n",
       "\n",
       "  home_market_value  home_owner  college_degree  good_credit acct_suspd_date  \\\n",
       "0     50000 - 74999           1               1            1             NaN   \n",
       "1     50000 - 74999           1               0            0             NaN   \n",
       "2     75000 - 99999           1               0            0             NaN   \n",
       "3   175000 - 199999           1               0            1      2021-12-22   \n",
       "4   225000 - 249999           1               1            1             NaN   \n",
       "\n",
       "   Churn  latitude_rounded  longitude_rounded  \n",
       "0      0             32.58             -96.31  \n",
       "1      0             32.73             -97.00  \n",
       "2      0             32.82             -96.85  \n",
       "3      1             32.68             -97.16  \n",
       "4      0             32.75             -97.38  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a49bfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "individual_id                0\n",
       "address_id                   0\n",
       "curr_ann_amt                 0\n",
       "days_tenure                  0\n",
       "cust_orig_date               0\n",
       "age_in_years                 0\n",
       "date_of_birth                0\n",
       "latitude                     0\n",
       "longitude                    0\n",
       "city                         0\n",
       "state                        0\n",
       "county                       0\n",
       "income                       0\n",
       "has_children                 0\n",
       "length_of_residence          0\n",
       "marital_status               0\n",
       "home_market_value            0\n",
       "home_owner                   0\n",
       "college_degree               0\n",
       "good_credit                  0\n",
       "acct_suspd_date        1476839\n",
       "Churn                        0\n",
       "latitude_rounded             0\n",
       "longitude_rounded            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39f2e1a",
   "metadata": {},
   "source": [
    "<p> We can drop the <b>'latitude_rounded'</b> and <b>'longitude_rounded'</b>, since we already have the original columns.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627b07b9",
   "metadata": {},
   "source": [
    "<p>The <b>'latitude'</b> and <b>'longitude'</b> columns are rounded to two decimal points and they represent with a precision of 1.1 kilometer or 0.7 miles at the equator.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198764f6",
   "metadata": {},
   "source": [
    "<p> Since we are not going to examine based on the region but not the exact address, the two decimal point precision will work just fine</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "892bb3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['latitude_rounded', 'longitude_rounded'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330abe54",
   "metadata": {},
   "source": [
    "<p>Let us make sure both the columns are dropped and then we will be ready to export the dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "effd8814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individual_id</th>\n",
       "      <th>address_id</th>\n",
       "      <th>curr_ann_amt</th>\n",
       "      <th>days_tenure</th>\n",
       "      <th>cust_orig_date</th>\n",
       "      <th>age_in_years</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>income</th>\n",
       "      <th>has_children</th>\n",
       "      <th>length_of_residence</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>home_market_value</th>\n",
       "      <th>home_owner</th>\n",
       "      <th>college_degree</th>\n",
       "      <th>good_credit</th>\n",
       "      <th>acct_suspd_date</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221300017872.00</td>\n",
       "      <td>521300005982.00</td>\n",
       "      <td>818.88</td>\n",
       "      <td>1454.00</td>\n",
       "      <td>2018-12-09</td>\n",
       "      <td>44</td>\n",
       "      <td>1978-06-23</td>\n",
       "      <td>32.58</td>\n",
       "      <td>-96.31</td>\n",
       "      <td>Kaufman</td>\n",
       "      <td>TX</td>\n",
       "      <td>Kaufman</td>\n",
       "      <td>22500.00</td>\n",
       "      <td>1</td>\n",
       "      <td>15.00</td>\n",
       "      <td>Married</td>\n",
       "      <td>50000 - 74999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221300134410.00</td>\n",
       "      <td>521300051115.00</td>\n",
       "      <td>974.20</td>\n",
       "      <td>1795.00</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>72</td>\n",
       "      <td>1950-05-30</td>\n",
       "      <td>32.73</td>\n",
       "      <td>-97.00</td>\n",
       "      <td>Grand Prairie</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>27500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Single</td>\n",
       "      <td>50000 - 74999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221300673028.00</td>\n",
       "      <td>521300247929.00</td>\n",
       "      <td>967.38</td>\n",
       "      <td>4818.00</td>\n",
       "      <td>2009-09-23</td>\n",
       "      <td>55</td>\n",
       "      <td>1967-07-07</td>\n",
       "      <td>32.82</td>\n",
       "      <td>-96.85</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>42500.00</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>Married</td>\n",
       "      <td>75000 - 99999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221301573419.00</td>\n",
       "      <td>521300570147.00</td>\n",
       "      <td>992.41</td>\n",
       "      <td>130.00</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>53</td>\n",
       "      <td>1969-05-25</td>\n",
       "      <td>32.68</td>\n",
       "      <td>-97.16</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>TX</td>\n",
       "      <td>Tarrant</td>\n",
       "      <td>125000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>6.00</td>\n",
       "      <td>Married</td>\n",
       "      <td>175000 - 199999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221301622347.00</td>\n",
       "      <td>521300588399.00</td>\n",
       "      <td>784.63</td>\n",
       "      <td>5896.00</td>\n",
       "      <td>2006-10-11</td>\n",
       "      <td>50</td>\n",
       "      <td>1972-09-25</td>\n",
       "      <td>32.75</td>\n",
       "      <td>-97.38</td>\n",
       "      <td>Fort Worth</td>\n",
       "      <td>TX</td>\n",
       "      <td>Tarrant</td>\n",
       "      <td>87500.00</td>\n",
       "      <td>1</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Married</td>\n",
       "      <td>225000 - 249999</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    individual_id      address_id  curr_ann_amt  days_tenure cust_orig_date  \\\n",
       "0 221300017872.00 521300005982.00        818.88      1454.00     2018-12-09   \n",
       "1 221300134410.00 521300051115.00        974.20      1795.00     2018-01-02   \n",
       "2 221300673028.00 521300247929.00        967.38      4818.00     2009-09-23   \n",
       "3 221301573419.00 521300570147.00        992.41       130.00     2022-07-25   \n",
       "4 221301622347.00 521300588399.00        784.63      5896.00     2006-10-11   \n",
       "\n",
       "   age_in_years date_of_birth  latitude  longitude           city state  \\\n",
       "0            44    1978-06-23     32.58     -96.31        Kaufman    TX   \n",
       "1            72    1950-05-30     32.73     -97.00  Grand Prairie    TX   \n",
       "2            55    1967-07-07     32.82     -96.85         Dallas    TX   \n",
       "3            53    1969-05-25     32.68     -97.16      Arlington    TX   \n",
       "4            50    1972-09-25     32.75     -97.38     Fort Worth    TX   \n",
       "\n",
       "    county    income  has_children  length_of_residence marital_status  \\\n",
       "0  Kaufman  22500.00             1                15.00        Married   \n",
       "1   Dallas  27500.00             0                 2.00         Single   \n",
       "2   Dallas  42500.00             0                10.00        Married   \n",
       "3  Tarrant 125000.00             1                 6.00        Married   \n",
       "4  Tarrant  87500.00             1                 4.00        Married   \n",
       "\n",
       "  home_market_value  home_owner  college_degree  good_credit acct_suspd_date  \\\n",
       "0     50000 - 74999           1               1            1             NaN   \n",
       "1     50000 - 74999           1               0            0             NaN   \n",
       "2     75000 - 99999           1               0            0             NaN   \n",
       "3   175000 - 199999           1               0            1      2021-12-22   \n",
       "4   225000 - 249999           1               1            1             NaN   \n",
       "\n",
       "   Churn  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      1  \n",
       "4      0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d49bfc",
   "metadata": {},
   "source": [
    "<p>As our dataset is clean now we can proceed and export it in the desired format.</p>\n",
    "<p>I am going to export it to csv format, since I can use it to import with Tableau Public.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7781cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Clean Data/autoinsurance_churn_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
